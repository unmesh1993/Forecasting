{"cells":[{"cell_type":"code","execution_count":106,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1744721800472,"user":{"displayName":"SHIPRA RANJAN","userId":"18109080763099856762"},"user_tz":-330},"id":"58pWNfaPP8ua"},"outputs":[],"source":["import yfinance as yf\n","import pandas as pd\n","import numpy as np\n","from datetime import date\n","import seaborn as sns\n","\n","import matplotlib.pyplot as plt\n","\n","\n","from sklearn.linear_model import Ridge\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n","from sklearn.preprocessing import MinMaxScaler\n","from scipy.stats import t\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.mixture import GaussianMixture\n","from statsmodels.tsa.statespace.sarimax import SARIMAX\n","from statsmodels.stats.diagnostic import acorr_ljungbox\n","\n","from scipy.stats import probplot\n","\n","from statsmodels.nonparametric.kde import KDEUnivariate\n","import statsmodels.api as sm\n","from statsmodels.tsa.stattools import adfuller, kpss\n","from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n","from statsmodels.tsa.statespace.sarimax import SARIMAX\n","from statsmodels.tsa.arima_process import ArmaProcess\n","\n","from tensorflow import keras\n","#from tensorflow.keras.utils import plot_model\n","\n","\n","######################################\n","#from pmdarima import auto_arima\n","#from diptest import diptest"]},{"cell_type":"code","execution_count":107,"metadata":{"id":"QLkUydaa0F0F","executionInfo":{"status":"ok","timestamp":1744721800593,"user_tz":-330,"elapsed":106,"user":{"displayName":"SHIPRA RANJAN","userId":"18109080763099856762"}}},"outputs":[],"source":["class prediction_analysis:\n","\n","    def __init__(self, df, y_pred, npast, nfuture):\n","        self.df = df\n","        self.y_pred = y_pred\n","        self.npast = npast\n","        self.nfuture = nfuture\n","\n","\n","    def plot_predictions(self):\n","        df_plot = self.df.iloc[self.npast:].copy()\n","        df_plot['Predicted_Close'] = self.y_pred\n","\n","        # Calculate percentage error\n","        df_plot['Prediction_Change_%'] = 100 * (df_plot['Close'] - df_plot['Predicted_Close']) / df_plot['Close']\n","        df_plot.dropna(inplace=True)\n","\n","        fig, axs = plt.subplots(4, 1, figsize=(12, 10))\n","        fig.subplots_adjust(hspace=0.5)\n","\n","        # --- Subplot 1: Time Series ---\n","        axs[0].plot(df_plot.index, df_plot['Close'], label='Actual Close', color='blue')\n","        axs[0].plot(df_plot.index, df_plot['Predicted_Close'], label='Predicted Close', linestyle='--', color='orange')\n","\n","        split_time = self.df.iloc[-self.nfuture].name\n","        axs[0].axvline(x=split_time, color='black', linestyle=':', label='Train/Test Split')\n","\n","        axs[0].set_title('Actual vs Predicted Close Prices')\n","        axs[0].set_xlabel('Date')\n","        axs[0].set_ylabel('Price')\n","        axs[0].legend()\n","        axs[0].grid(True)\n","        axs[0].set_xlim(self.df.index[-2 * self.nfuture], self.df.index[-1] )\n","\n","        # --- Subplot 2: % Error vs Actual Price ---\n","        axs[1].scatter(df_plot.index, df_plot['Prediction_Change_%'], alpha=0.6, color='green')\n","        axs[1].axhline(y=0, color='red', linestyle='--', label='No Error')\n","        split_time = self.df.iloc[-self.nfuture].name\n","        axs[1].axvline(x=split_time, color='black', linestyle=':', label='Train/Test Split')\n","\n","        axs[1].set_title('Percentage Prediction Error vs Actual Price')\n","        axs[1].set_xlabel('Date')\n","        axs[1].set_ylabel('Prediction_Change_%')\n","        axs[1].legend()\n","        axs[1].grid(True)\n","        axs[1].set_ylim(-20, 20)\n","\n","    #subplot 3\n","        test_preds = df_plot.iloc[-self.nfuture:]['Prediction_Change_%'].values\n","\n","        # Fit a Student's t-distribution to the data\n","        df_t, loc_t, scale_t = t.fit(test_preds)\n","\n","        # Compute statistics from t-distribution\n","        mean_pred = loc_t\n","        std_pred = scale_t * np.sqrt(df_t / (df_t - 2)) if df_t > 2 else np.inf\n","        ci_lower, ci_upper = t.interval(0.95, df_t, loc=loc_t, scale=scale_t)\n","\n","        # Plot histogram with KDE\n","        sns.histplot(test_preds, kde=True, bins=50, color='skyblue', edgecolor='black', ax=axs[2])\n","\n","        # Plot mean\n","        axs[2].axvline(mean_pred, color='red', linestyle='-', label=f'Mean (t-fit): {mean_pred:.2f}')\n","\n","        # Plot Â±1Ïƒ range\n","        axs[2].axvline(mean_pred - std_pred, color='purple', linestyle='--', label=f'-1Ïƒ: {mean_pred - std_pred:.2f}')\n","        axs[2].axvline(mean_pred + std_pred, color='purple', linestyle='--', label=f'+1Ïƒ: {mean_pred + std_pred:.2f}')\n","\n","        # Plot 95% confidence interval (CI)\n","        axs[2].axvspan(ci_lower, ci_upper, color='gray', alpha=0.3, label=f'95% CI (t-fit): {ci_lower:.2f} - {ci_upper:.2f}')\n","\n","        # Plot formatting\n","        axs[2].set_title('Histogram of Prediction_Change_% (Test Set) with T-Distribution Fit')\n","        axs[2].set_xlabel('Prediction_Change_%')\n","        axs[2].set_ylabel('Frequency')\n","        axs[2].legend()\n","        axs[2].grid(True)\n","        axs[2].set_xlim(mean_pred - 4 * std_pred, mean_pred + 4 * std_pred)\n","\n","        # --- Subplot 4: Bimodal Distribution with Gaussian Mixture Model ---\n","        gmm = GaussianMixture(n_components=2, random_state=42)\n","        gmm.fit(test_preds.reshape(-1, 1))\n","        labels = gmm.predict(test_preds.reshape(-1, 1))\n","\n","        # Extract means and variances of both components\n","        means = gmm.means_.flatten()\n","        variances = gmm.covariances_.flatten()\n","\n","        sns.histplot(test_preds, bins=30, kde=True, color=\"gray\", alpha=0.5, ax=axs[3])\n","        axs[3].scatter(test_preds, [-0.01]*len(test_preds), c=labels, cmap=\"coolwarm\", s=5)\n","        axs[3].set_title(f\"GMM Fit: Mean1={means[0]:.2f}, Var1={variances[0]:.2f} | Mean2={means[1]:.2f}, Var2={variances[1]:.2f}\")\n","\n","\n","        prediction = self.y_pred[-1]\n","        mean=df_plot['Prediction_Change_%'].mean()\n","        std=df_plot['Prediction_Change_%'].std()\n","        ci_lower, ci_upper = t.interval(0.95, df_t, loc=loc_t, scale=scale_t)\n","\n","        # Corrected prediction\n","        corrected = prediction * (1 + mean / 100)\n","\n","        # 95% CI bounds\n","        ci_low = prediction * (1 + ci_lower / 100)\n","        ci_high = prediction * (1 + ci_upper / 100)\n","\n","        # Print results\n","        print(\"Actual + 1 year:\" , self.df.iloc[-1, 0])\n","        print(f\"Prediction + 1 year: {prediction:.2f}\")\n","        print(f\"Corrected Prediction: {corrected:.2f}\")\n","        print(f\"95% Confidence Interval: [{ci_low:.2f}, {ci_high:.2f}]\")\n","        print(f\"Â±1 Standard Deviation Range: [{prediction * (1 + (mean - std)/100):.2f}, {prediction * (1 + (mean + std)/100):.2f}]\")\n","\n"]},{"cell_type":"code","source":["class TimeSeriesTransformer:\n","    def __init__(self):\n","        self.series = None\n","\n","    def difference(self, n=1, plot=True):\n","        diff = self.series.diff(n)\n","        if plot:\n","            plt.figure(figsize=(12, 5))\n","            plt.plot(diff, label=f\"{n}-th Order Difference\", color=\"blue\")\n","            plt.axhline(y=0, color='black', linestyle='dashed', linewidth=0.8)\n","            plt.title(f\"{n}-th Order Differencing\")\n","            plt.legend()\n","            plt.show()\n","        return diff\n","\n","    def reverse_difference(self, diff_series, order=1):\n","        reversed_series = diff_series.copy()\n","        for i in range(order, 0, -1):\n","            reversed_series = reversed_series.cumsum() + self.series.iloc[i - 1]\n","        return reversed_series\n","\n","    def log_difference(self, n=1, plot=True):\n","        log_series = np.log(self.series).dropna()\n","        diff = log_series.diff(n).dropna() if n > 0 else log_series\n","        if plot:\n","            plt.figure(figsize=(12, 5))\n","            plt.plot(diff, label=f\"{n}-th Order Log Difference\", color=\"purple\")\n","            plt.axhline(y=0, color='black', linestyle='dashed', linewidth=0.8)\n","            plt.title(f\"{n}-th Order Log Differencing\")\n","            plt.legend()\n","            plt.show()\n","        return diff\n","\n","    def reverse_log_difference(self, diff_series):\n","        reversed_series = diff_series.cumsum() + np.log(self.series.iloc[-1])\n","        return np.exp(reversed_series).dropna()\n","\n","    def check_stationarity(self, df, window=30, lags=30):\n","        self.series=df\n","\n","        # Rolling Mean & Standard Deviation\n","        rolling_mean = self.series.rolling(window=window).mean()\n","        rolling_std = self.series.rolling(window=window).std()\n","\n","        fig, ax1 = plt.subplots(figsize=(10, 5))\n","        ax1.plot(self.series, label=\"Original\", color=\"gray\", alpha=0.5)\n","        ax1.plot(rolling_mean, label=\"Rolling Mean\", color=\"blue\")\n","        ax1.axhline(y=0, color='black', linestyle='dashed', linewidth=0.8)\n","        ax1.legend(loc=\"upper left\")\n","\n","        ax2 = ax1.twinx()\n","        ax2.plot(rolling_std, label=\"Rolling Std Dev\", color=\"red\", linestyle=\"dashed\", alpha=0.7)\n","        ax2.legend(loc=\"upper right\")\n","\n","        plt.title(\"Rolling Mean & Std Deviation\")\n","        plt.show()\n","\n","        # Augmented Dickey-Fuller Test\n","        adf_result = adfuller(self.series.dropna())\n","        print(\"ðŸ”¹ ADF Test\")\n","        print(f\"ADF Statistic: {adf_result[0]:.4f}, p-value: {adf_result[1]:.4f}\")\n","        print(\"âœ… Stationary\" if adf_result[1] < 0.05 else \"âŒ Not Stationary\")\n","\n","        # KPSS Test\n","        kpss_stat, kpss_p, _, crit = kpss(self.series.dropna(), regression='c')\n","        print(\"\\nðŸ”¹ KPSS Test\")\n","        print(f\"KPSS Statistic: {kpss_stat:.4f}, p-value: {kpss_p:.4f}\")\n","        print(\"âœ… Stationary\" if kpss_p > 0.05 else \"âŒ Not Stationary\")\n","\n","        # ACF and PACF\n","        plt.figure(figsize=(12, 5))\n","        plot_acf(self.series.dropna(), lags=lags)\n","        plt.title(\"Autocorrelation Function (ACF)\")\n","        plt.show()\n","\n","        plt.figure(figsize=(12, 5))\n","        plot_pacf(self.series.dropna(), lags=lags)\n","        plt.title(\"Partial Autocorrelation Function (PACF)\")\n","        plt.show()\n"],"metadata":{"id":"RRnESAaPiLQp","executionInfo":{"status":"ok","timestamp":1744723806150,"user_tz":-330,"elapsed":23,"user":{"displayName":"SHIPRA RANJAN","userId":"18109080763099856762"}}},"execution_count":142,"outputs":[]},{"cell_type":"code","source":["class SARIMAModel:\n","    def __init__(self):\n","        self.order = None          #(1, 1, 1)\n","        self.seasonal_order = None #(1, 1, 1, 12)\n","        self.model = None\n","\n","    def train(self, data):\n","        self.model = SARIMAX(data, order=self.order, seasonal_order=self.seasonal_order).fit()\n","\n","    def predict(self, steps):\n","        return self.model.forecast(steps=steps)\n"],"metadata":{"id":"KF6UnlwVQK4A","executionInfo":{"status":"ok","timestamp":1744723027795,"user_tz":-330,"elapsed":4,"user":{"displayName":"SHIPRA RANJAN","userId":"18109080763099856762"}}},"execution_count":125,"outputs":[]},{"cell_type":"code","source":["class LSTMModel:\n","    def __init__(self, sequence_length):\n","\n","        # Define model architecture\n","        inputs = keras.Input(shape=(sequence_length, 1 ))\n","        x = keras.layers.LSTM(252, return_sequences=True)(inputs)\n","        x = keras.layers.Dropout(0.3)(x)\n","        x = keras.layers.LSTM(252, return_sequences=True)(x)\n","        x = keras.layers.Dropout(0.3)(x)\n","        x = keras.layers.LSTM(252)(x)\n","        outputs = keras.layers.Dense(1, activation='relu')(x)\n","\n","        # Compile model\n","        self.model = keras.Model(inputs=inputs, outputs=outputs)\n","        self.model.compile(optimizer='adam', loss=\"mse\")\n","        self.model.summary()\n","\n","    def train(self, X_train, y_train, columns, epochs=25, batch_size=32):\n","        x_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n","        self.model.fit(x_train, y_train, epochs=20, batch_size=32, validation_split = 0.2)\n","\n","    def predict(self, x_test):\n","        x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n","        return self.model.predict(x_test)"],"metadata":{"id":"e3fJQy7DQGhd","executionInfo":{"status":"ok","timestamp":1744721800599,"user_tz":-330,"elapsed":13,"user":{"displayName":"SHIPRA RANJAN","userId":"18109080763099856762"}}},"execution_count":109,"outputs":[]},{"cell_type":"code","source":["class SimpleNNModel:\n","    def __init__(self, sequence_length):\n","        # Define model architecture\n","        inputs = keras.Input(shape=(sequence_length,))\n","        x = keras.layers.Dense(128, activation='relu')(inputs)\n","        x = keras.layers.Dense(64, activation='relu')(x)\n","        x = keras.layers.Dense(32, activation='relu')(x)\n","        outputs = keras.layers.Dense(1, activation='relu')(x)\n","\n","        # Compile model\n","        self.model = keras.Model(inputs=inputs, outputs=outputs)\n","        self.model.compile(optimizer='adam', loss=\"mse\")\n","        self.model.summary()\n","\n","    def train(self, X_train, y_train, column, epochs=25, batch_size=32):\n","        # No reshaping needed for simple NN\n","        self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n","\n","    def predict(self, x_test):\n","        return self.model.predict(x_test)"],"metadata":{"id":"J6nTLUjnD8FJ","executionInfo":{"status":"ok","timestamp":1744721800601,"user_tz":-330,"elapsed":12,"user":{"displayName":"SHIPRA RANJAN","userId":"18109080763099856762"}}},"execution_count":110,"outputs":[]},{"cell_type":"code","source":["class RandomForestModel:\n","    def __init__(self):\n","        self.model = RandomForestRegressor(n_estimators=100, random_state=42)\n","\n","    def train(self, x_train, y_train, columns):\n","        self.model.fit(x_train, y_train)\n","\n","    def predict(self, x_test):\n","        return self.model.predict(x_test)"],"metadata":{"id":"-jOlVBMBQEfg","executionInfo":{"status":"ok","timestamp":1744721800615,"user_tz":-330,"elapsed":11,"user":{"displayName":"SHIPRA RANJAN","userId":"18109080763099856762"}}},"execution_count":111,"outputs":[]},{"cell_type":"code","execution_count":112,"metadata":{"id":"VTzP14ZeobC6","executionInfo":{"status":"ok","timestamp":1744721800617,"user_tz":-330,"elapsed":4,"user":{"displayName":"SHIPRA RANJAN","userId":"18109080763099856762"}}},"outputs":[],"source":["class RidgeModel:\n","    def __init__(self):\n","        self.model = Ridge()\n","\n","    def train(self, x_train, y_train, columns):\n","        self.model.fit(x_train, y_train)\n","\n","\n","        # Create summary DataFrame\n","        summary = pd.DataFrame({\n","            'Feature': columns,\n","            'Coefficient': self.model.coef_\n","        })\n","        plt.figure(figsize=(8, 4))\n","        plt.bar(summary['Feature'], summary['Coefficient'])\n","        plt.title('Feature Coefficients')\n","        plt.xlabel('Feature')\n","        plt.ylabel('Coefficient')\n","        plt.xticks(rotation=45)\n","\n","        y_train_p = self.model.predict(x_train)\n","        # Metrics\n","        mse = mean_squared_error(y_train, y_train_p)                       # MSE: mean((y - yÌ‚)^2)\n","        rmse = np.sqrt(mse)                                                # RMSE: sqrt(MSE)\n","        mae = mean_absolute_error(y_train, y_train_p)                      # MAE: mean(|y - yÌ‚|)\n","        mape = mean_absolute_percentage_error(y_train, y_train_p) * 100    # MAPE: mean(|(y - yÌ‚)/y|) * 100\n","        r2 = r2_score(y_train, y_train_p)                                  # R2: 1 - (MSE / variance(y))\n","\n","        print(\"Training Metrics:\")\n","        print(f\"  - MSE  = {mse:.4f}\")\n","        print(f\"  - RMSE = {rmse:.4f}\")\n","        print(f\"  - MAE  = {mae:.4f}\")\n","        print(f\"  - MAPE = {mape:.2f}%\")\n","        print(f\"  - R2 score = {r2:.2f}%\")\n","\n","\n","    def predict(self, x_test):\n","        return self.model.predict(x_test)"]},{"cell_type":"code","execution_count":113,"metadata":{"id":"fwT9opQtLvSa","executionInfo":{"status":"ok","timestamp":1744721800621,"user_tz":-330,"elapsed":2,"user":{"displayName":"SHIPRA RANJAN","userId":"18109080763099856762"}}},"outputs":[],"source":["class NoiseGenerator:\n","    def __init__(self, noise_type='gaussian', mu=0.0, sigma=1.0, s0=0, dt=1, seed=42):\n","        self.noise_type = noise_type\n","        self.mu = mu\n","        self.sigma = sigma\n","        self.s0 = s0\n","        self.dt = dt\n","        np.random.seed(seed)  # For reproducibility\n","        self.n = None\n","\n","    def generate(self, n):\n","        self.n=n\n","\n","        if self.noise_type == 'gaussian':\n","            return self._gaussian()\n","        elif self.noise_type == 'brownian':\n","            return self._brownian()\n","        elif self.noise_type == 'exponential_brownian':\n","            return self._exponential_brownian()\n","        else:\n","            raise ValueError(\"Invalid noise type. Choose from 'gaussian', 'brownian', or 'exponential_brownian'.\")\n","\n","    def _gaussian(self):\n","        \"\"\"Generates Gaussian (normal) noise.\"\"\"\n","        return np.random.normal(self.mu, self.sigma, self.n)\n","\n","    def _brownian(self):\n","        \"\"\"Generates Brownian motion (Wiener process).\"\"\"\n","        w = np.random.normal(self.mu, np.sqrt(self.dt), self.n).cumsum()\n","        return self.s0 + self.mu * np.arange(self.n) * self.dt + self.sigma * w\n","\n","    def _exponential_brownian(self):\n","        \"\"\"Generates Exponential Brownian Motion (Geometric Brownian Motion).\"\"\"\n","        w = np.random.normal(0, np.sqrt(self.dt), self.n).cumsum()\n","        time = np.linspace(0, self.n * self.dt, self.n)\n","        return self.s0 * np.exp((self.mu - 0.5 * self.sigma**2) * time + self.sigma * w)"]},{"cell_type":"code","execution_count":114,"metadata":{"id":"F8wISQmbNqzg","executionInfo":{"status":"ok","timestamp":1744721800626,"user_tz":-330,"elapsed":2,"user":{"displayName":"SHIPRA RANJAN","userId":"18109080763099856762"}}},"outputs":[],"source":["class StockData:\n","    def __init__(self, ticker, start, end, column):\n","        self.ticker = ticker\n","        self.start = start\n","        self.end = end\n","        self.df = None\n","        self.column=column\n","\n","    def fetch_data(self):\n","        self.df = yf.download(self.ticker, start=self.start, end=self.end)\n","\n","        self.df = self.df.sort_index()\n","        self.df = self.df.dropna()\n","        self.df.info()\n","\n","        #PLOT\n","        ax = self.df.drop(columns=[\"Volume\"]).plot(figsize=(12, 6), title=self.ticker + \"Stock Prices\")\n","        ax.set_ylabel(\"Stock Price\")\n","        ax2 = ax.twinx()\n","        ax2.set_ylabel(\"Volume\")\n","        ax2.plot(self.df.index, self.df[\"Volume\"], color=\"gray\", alpha=0.5, linestyle=\"dashed\", label=\"Volume\")\n","        ax2.legend(loc=\"upper left\")\n","        plt.show()\n","\n","        self.df.columns = self.df.columns.get_level_values(0)\n","        new_df = self.df[[self.column]].copy()\n","        new_df.info()\n","        self.CAGR(new_df)\n","        return new_df\n","\n","    def CAGR(self, df):\n","        # Ensure the DataFrame index is datetime\n","        df = df.sort_index()\n","        if not isinstance(df.index, pd.DatetimeIndex):\n","            raise ValueError(\"DataFrame index must be a DatetimeIndex.\")\n","\n","        yearly_cagr = {}\n","        cumulative_cagr = {}\n","\n","        years = sorted(df.index.year.unique())\n","\n","        # Use the second year as the start to avoid incomplete initial data\n","        start_year = years[1]\n","        start_date = df[df.index.year == start_year].index[0]\n","        start_value = df.loc[start_date].values[0]\n","\n","        for year in years[1:]:  # Skip the first year\n","            # Yearly CAGR\n","            yearly_df = df[df.index.year == year]\n","            start = yearly_df.iloc[0].values[0]\n","            end = yearly_df.iloc[-1].values[0]\n","            days = (yearly_df.index[-1] - yearly_df.index[0]).days\n","            if days > 0:\n","                yearly_cagr[year] = (end / start) ** (365.25 / days) - 1\n","\n","            # Cumulative CAGR from start_year to current year\n","            end_value = df[df.index.year <= year].iloc[-1].values[0]\n","            total_days = (df[df.index.year <= year].index[-1] - start_date).days\n","            if total_days > 0:\n","                cumulative_cagr[year] = (end_value / start_value) ** (365.25 / total_days) - 1\n","\n","        # Plot\n","        plt.figure(figsize=(12, 6))\n","\n","        # Yearly CAGR line\n","        plt.plot(yearly_cagr.keys(), [v * 100 for v in yearly_cagr.values()],\n","                marker='o', label='Yearly CAGR')\n","\n","        # Cumulative CAGR line\n","        cumulative_values = [v * 100 for v in cumulative_cagr.values()]\n","        plt.plot(cumulative_cagr.keys(), cumulative_values,\n","                marker='s', linestyle='--', label='Cumulative CAGR')\n","\n","        # Annotate cumulative CAGR values\n","        for year, val in cumulative_cagr.items():\n","            plt.text(year, val * 100 + 0.5, f\"{val * 100:.2f}%\", ha='center', fontsize=8, color='blue')\n","\n","        plt.axhline(0, color='black', linewidth=0.5)\n","        plt.title(\"Yearly vs Cumulative CAGR of NIFTY Close Prices\")\n","        plt.xlabel(\"Year\")\n","        plt.ylabel(\"CAGR (%)\")\n","        plt.grid(True)\n","        plt.legend()\n","        plt.xlim(2007, 2025)\n","        plt.xticks(range(2007, 2026, 1))\n","        plt.tight_layout()\n","        plt.show()"]},{"cell_type":"code","source":["class features_ml:\n","\n","    def __init__(self, df, noise_generator, npast, column, param = 252, split_type='index'):\n","        self.df = df.copy()\n","        self.noise_generator = noise_generator\n","        self.npast = npast\n","        self.split_type = split_type\n","        self.param = param\n","        self.column=column\n","        self.X=None\n","        self.Y=None\n","\n","    def features(self):\n","        self.df[\"date\"] = self.df.index\n","        self.df[\"year\"] = self.df[\"date\"].dt.year\n","        self.df[\"month\"] = self.df[\"date\"].dt.month\n","        #self.df[\"day\"] = self.df[\"date\"].dt.day\n","        #self.df['day_of_year'] = self.df[\"date\"].dt.dayofyear\n","        self.df.drop(columns=[\"date\"], inplace=True)\n","\n","        self.df['Noise'] = self.noise_generator.generate(self.df.shape[0])\n","\n","        for lag in range(1, self.npast + 1):\n","            self.df[f'lag{lag}'] = self.df[self.column].shift(lag)\n","\n","        self.df.dropna(inplace=True)\n","\n","        self.y = self.df[self.column].copy()\n","        self.X = self.df.drop(columns=self.column).copy()\n","        self.X.info()\n","        return self.X, self.y"],"metadata":{"id":"CTrm1fnHmCEO","executionInfo":{"status":"ok","timestamp":1744721800636,"user_tz":-330,"elapsed":8,"user":{"displayName":"SHIPRA RANJAN","userId":"18109080763099856762"}}},"execution_count":115,"outputs":[]},{"cell_type":"code","execution_count":116,"metadata":{"id":"I8WaLmIcPJjC","executionInfo":{"status":"ok","timestamp":1744721800671,"user_tz":-330,"elapsed":17,"user":{"displayName":"SHIPRA RANJAN","userId":"18109080763099856762"}}},"outputs":[],"source":["class FutureDataPoint:\n","    def __init__(self, X_train_last, y_train_pred_npast , model, scaler, npast, noise_generator, column):\n","        self.X_new = X_train_last.copy()\n","        self.y_train_pred_npast = y_train_pred_npast.copy()\n","        self.model = model\n","        self.scaler = scaler\n","        self.npast = npast\n","        self.noise_generator = noise_generator\n","        self.column = column\n","\n","    def predict_future_steps(self, nfuture):\n","        y_test_pred = []\n","        for i in range(nfuture):\n","\n","            next_index = self.X_new.index[0] + pd.tseries.offsets.BDay(1) # Set the next business day as the index\n","            self.X_new.index = [next_index]\n","\n","            y_next = self.generate_datapoint_predict()\n","            y_test_pred.append(y_next)\n","\n","        return np.array(y_test_pred)\n","\n","    def generate_datapoint_predict(self):\n","        self.X_new[\"date\"] = self.X_new.index\n","        self.X_new[\"year\"] = self.X_new[\"date\"].dt.year\n","        self.X_new[\"month\"] = self.X_new[\"date\"].dt.month\n","        #self.X_new[\"day\"] = self.X_new[\"date\"].dt.day\n","        #self.X_new[\"day_of_year\"] = self.X_new[\"date\"].dt.dayofyear\n","        self.X_new.drop(columns=[\"date\"], inplace=True)\n","\n","        # Add noise to the dataset\n","        self.X_new['Noise'] = self.noise_generator.generate(1)\n","\n","        #add lags from predictions\n","        for i in range(1, self.npast+1):\n","            self.X_new[f'lag{i}'] = self.y_train_pred_npast[-i]\n","        self.X_new.dropna(inplace=True)\n","\n","        # Scale the new data point\n","        X_new_scaled = self.scaler.transform(self.X_new)\n","\n","        # Predict next value\n","        y_next = self.model.predict(X_new_scaled)\n","\n","        for i in range(0,self.npast-1):\n","          self.y_train_pred_npast[i+1] = self.y_train_pred_npast[i]\n","        self.y_train_pred_npast[0] = y_next.flatten()[0]\n","\n","        return y_next"]},{"cell_type":"code","execution_count":144,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1744723867587,"user":{"displayName":"SHIPRA RANJAN","userId":"18109080763099856762"},"user_tz":-330},"id":"cRzFq8xiNyGI"},"outputs":[],"source":["class StockPredictor:\n","    def __init__(self, ticker, start, end, column ,noise_generator, nfuture = 252):\n","\n","        self.ticker = ticker\n","        self.start = start\n","        self.end = end\n","        self.model_type = None\n","        self.df=None\n","        self.scaler = MinMaxScaler(feature_range=(0, 1))\n","        self.nfuture = nfuture\n","        self.noise_generator = noise_generator\n","        self.column=column\n","\n","    def data_initiation(self):\n","        self.df = StockData(self.ticker, self.start, self.end, self.column).fetch_data()\n","\n","    def run_ml(self, npast, model_type):\n","\n","        if model_type == 'RidgeModel':\n","            self.model = RidgeModel()\n","        elif model_type == 'RandomForestModel':\n","            self.model = RandomForestModel()\n","        elif model_type == 'SimpleNNModel':\n","            self.model = SimpleNNModel(sequence_length=self.npast + 3)\n","        elif model_type == 'LSTMModel':\n","            self.model = LSTMModel(sequence_length=self.npast + 3)\n","        elif model_type == 'SARIMAModel':\n","            self.model = SARIMAModel()\n","        else:\n","            raise ValueError(\"Unsupported model type\")\n","\n","\n","        #prepare features\n","        X, y = features_ml(self.df, self.noise_generator, npast, self.column, param = self.nfuture, split_type='index').features()\n","\n","        #test-train data :ML\n","        split_index = int(X.shape[0] - self.nfuture)\n","        X_train, X_test = X[:split_index], X[split_index:]\n","        y_train, y_test = y[:split_index], y[split_index:]\n","\n","        #train\n","        X_train_scaled = self.scaler.fit_transform(X_train)\n","        self.model.train(X_train_scaled, y_train, list(X.columns))\n","\n","        #predict\n","        y_train_pred = self.model.predict(X_train_scaled)\n","        y_test_pred = FutureDataPoint(X_train.iloc[[-1]], y_train_pred[-npast:] , self.model, self.scaler, npast, self.noise_generator, self.column).predict_future_steps(self.nfuture)\n","\n","        #analysis\n","        y_pred=np.concatenate((y_train_pred.flatten(), y_test_pred.flatten()))\n","        prediction_analysis(self.df, y_pred, npast, self.nfuture).plot_predictions()\n","\n","\n","    def run_ts(self, npast, model_type):\n","        if model_type == 'SARIMAModel':\n","            self.model = SARIMAModel()\n","\n","        #check_stationarity\n","        TimeSeriesTransformer.check_stationarity(self.df[self.column])\n","\n","\n"]},{"cell_type":"code","source":["noise_generator = NoiseGenerator(noise_type='gaussian', mu=0, sigma=1, s0=0, dt=1)\n","\n","predictor = StockPredictor('^NSEI', '2000-01-01', date.today(), 'Close', noise_generator, nfuture = 252)\n","predictor.data_initiation()"],"metadata":{"id":"tN4NqWJOI8ji"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ts_models = ['SARIMAModel']\n","predictor.run_ts(npast=10, model_type=ts_models[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":280},"id":"oRBmAGfkmuaB","executionInfo":{"status":"error","timestamp":1744723871967,"user_tz":-330,"elapsed":46,"user":{"displayName":"SHIPRA RANJAN","userId":"18109080763099856762"}},"outputId":"fa89c6e8-649a-4592-b0d9-49889b8587bf"},"execution_count":145,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"TimeSeriesTransformer.check_stationarity() missing 1 required positional argument: 'df'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-145-99fe6828e313>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mts_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'SARIMAModel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_ts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mts_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-129-aa623f4e5ad2>\u001b[0m in \u001b[0;36mrun_ts\u001b[0;34m(self, npast, model_type)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m#check_stationarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mTimeSeriesTransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_stationarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: TimeSeriesTransformer.check_stationarity() missing 1 required positional argument: 'df'"]}]},{"cell_type":"code","execution_count":135,"metadata":{"id":"k0qIu3xbQZZ6","executionInfo":{"status":"ok","timestamp":1744723379133,"user_tz":-330,"elapsed":3,"user":{"displayName":"SHIPRA RANJAN","userId":"18109080763099856762"}}},"outputs":[],"source":["ml_models = ['RidgeModel', 'RandomForestModel', 'SimpleNNModel','LSTMModel']\n","#predictor.run_ml(npast=10, model_type=ml_models[0])"]},{"cell_type":"code","source":[],"metadata":{"id":"CIUq4YR8ffFN","executionInfo":{"status":"aborted","timestamp":1744721800867,"user_tz":-330,"elapsed":14,"user":{"displayName":"SHIPRA RANJAN","userId":"18109080763099856762"}}},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMmyDuFaBy/YdSiHVgLCfz7"},"kernelspec":{"display_name":"Python [conda env:base] *","language":"python","name":"conda-base-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"}},"nbformat":4,"nbformat_minor":0}