{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPsBGjo7vyiaQ9qhDh1K8hZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"c-5xLyx46jZ2"},"outputs":[],"source":["import yfinance as yf\n","import pandas as pd\n","import numpy as np\n","from datetime import date\n","import seaborn as sns\n","import random\n","\n","import matplotlib.pyplot as plt\n","\n","from sklearn.linear_model import Ridge\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.mixture import GaussianMixture\n","\n","\n","from statsmodels.tsa.statespace.sarimax import SARIMAX\n","from statsmodels.stats.diagnostic import acorr_ljungbox\n","\n","import scipy.stats as stats\n","from scipy.stats import probplot, laplace, norm, t\n","\n","\n","import statsmodels.api as sm\n","from statsmodels.nonparametric.kde import KDEUnivariate\n","from statsmodels.tsa.stattools import adfuller, kpss\n","from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n","from statsmodels.tsa.statespace.sarimax import SARIMAX\n","from statsmodels.tsa.arima_process import ArmaProcess\n","\n","import pymc as pm\n","import pytensor.tensor as pt\n","import arviz as az\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","\n","#from tensorflow.keras.utils import plot_model\n","\n","\n","######################################\n","#from pmdarima import auto_arima\n","#from diptest import diptest"]},{"cell_type":"code","source":["class Bayesian_PP:\n","    def __init__(self):\n","        self.log_returns = None\n","        self.df=None\n","\n","        self.mu_prior = None\n","        self.sigma_prior = None\n","        self.mu_j_prior = None\n","        self.sigma_j_prior = None\n","        self.lamda_j_prior = None\n","\n","        self.mu_samples = None\n","        self.sigma_samples = None\n","        self.mu_j_samples = None\n","        self.sigma_j_samples = None\n","        self.lamda_j_samples = None\n","\n","    def log_return_GBM(self, df):\n","        self.df=df\n","        df['log_return'] = np.log(self.df / self.df.shift(1))\n","        self.log_returns = df['log_return'].dropna()\n","\n","        log_returns_values = self.log_returns.values\n","        mu_est, sigma_est = stats.norm.fit(log_returns_values)\n","\n","        mu = mu_est + 0.5 *sigma_est**2\n","        sigma = sigma_est/np.sqrt(1)  #since the data is for each day\n","\n","        # Compute annualized values\n","        mu_annual = mu * 252\n","        sigma_annual = sigma * np.sqrt(252)\n","\n","        mu_daily_rounded, sigma_daily_rounded, mu_annual_rounded, sigma_annual_rounded  = round(mu * 100, 2), round(sigma * 100, 2), round(mu_annual * 100, 2), round(sigma_annual * 100, 2)\n","        print(f\"Daily mu (sigma) = {mu_daily_rounded}% ± {sigma_daily_rounded}%\")\n","        print(f\"Annual mu (sigma) = {mu_annual_rounded}% ± {sigma_annual_rounded}%\")\n","\n","        # Setup subplots\n","        fig, axs = plt.subplots(3, 1, figsize=(12, 12), constrained_layout=True)\n","\n","        # ─────────────────────────────\n","        # 1️⃣ Time Series Plot\n","        axs[0].plot(self.log_returns, label='Log Returns')\n","        axs[0].axhline(mu - 1*sigma, color='b', linestyle='--', label=f'μ - 1σ = {mu - 3*sigma:.4f}')\n","        axs[0].axhline(mu + 1*sigma, color='b', linestyle='--', label=f'μ + 1σ = {mu + 3*sigma:.4f}')\n","        axs[0].set_title('Daily Log Returns (Time Series)', fontsize=14)\n","        axs[0].set_xlabel('Date')\n","        axs[0].set_ylabel('Log Return')\n","        axs[0].legend()\n","        axs[0].grid(True)\n","\n","        # ─────────────────────────────\n","        # 2️⃣ Histogram + Gaussian Fit\n","        x = np.linspace(self.log_returns.min(), self.log_returns.max(), 1000)\n","        pdf = stats.norm.pdf(x, mu, sigma)\n","\n","        axs[1].hist(log_returns_values, bins=50, density=True, alpha=0.6, edgecolor='k', label='Histogram')\n","        axs[1].plot(x, pdf, 'r-', label=f'Gaussian Fit\\nμ={mu:.4f}, σ={sigma:.4f}')\n","        axs[1].axvline(mu - 1*sigma, color='b', linestyle='--', label=f'μ - 1σ = {mu - 3*sigma:.4f}')\n","        axs[1].axvline(mu + 1*sigma, color='b', linestyle='--', label=f'μ + 1σ = {mu + 3*sigma:.4f}')\n","        axs[1].set_title('Log Returns Distribution & Gaussian Fit', fontsize=14)\n","        axs[1].set_xlabel('Log Return')\n","        axs[1].set_ylabel('Density')\n","        axs[1].legend()\n","        axs[1].grid(True)\n","\n","        # ─────────────────────────────\n","        # 3️⃣ Q-Q Plot\n","        stats.probplot(log_returns_values, dist=\"norm\", plot=axs[2])\n","        axs[2].get_lines()[1].set_color('red')  # Line of best fit\n","        axs[2].set_title('Q-Q Plot of Log Returns', fontsize=14)\n","        axs[2].grid(True)\n","\n","        # Show all\n","        plt.show()\n","\n","        self.mu_prior = mu_annual\n","        self.sigma_prior = sigma_annual\n","\n","        return self.mu_prior, self.sigma_prior,\n","\n","    def log_return_Merton(self, df):\n","        self.df=df\n","        df['log_return'] = np.log(self.df / self.df.shift(1))\n","        self.log_returns = df['log_return'].dropna()\n","\n","        sorted = self.log_returns.sort_index()\n","\n","        # Remove outliers using IQR method\n","        qv1 = sorted.quantile(0.25)\n","        qv2 = sorted.quantile(0.75)\n","        iqr = qv2 - qv1\n","        lower_bound = qv1 - 1.5 * iqr\n","        upper_bound = qv2 + 1.5 * iqr\n","\n","        # Filter out outliers\n","        filtered_sorted = sorted[(sorted >= lower_bound) & (sorted <= upper_bound)]\n","        log_returns_values = filtered_sorted.values\n","\n","        mu_est, sigma_est = stats.norm.fit(log_returns_values)\n","\n","        mu = mu_est + 0.5 *sigma_est**2\n","        sigma = sigma_est/np.sqrt(1)  #since the data is for each day\n","\n","        # Compute annualized values\n","        mu_annual = mu * 252\n","        sigma_annual = sigma * np.sqrt(252)\n","\n","        mu_daily_rounded, sigma_daily_rounded, mu_annual_rounded, sigma_annual_rounded  = round(mu * 100, 2), round(sigma * 100, 2), round(mu_annual * 100, 2), round(sigma_annual * 100, 2)\n","        print(f\"Daily mu (sigma) = {mu_daily_rounded}% ± {sigma_daily_rounded}%\")\n","        print(f\"Annual mu (sigma) = {mu_annual_rounded}% ± {sigma_annual_rounded}%\")\n","\n","        # Setup subplots\n","        fig, axs = plt.subplots(3, 1, figsize=(12, 12), constrained_layout=True)\n","\n","        # ─────────────────────────────\n","        # 1️⃣ Time Series Plot\n","        axs[0].plot(self.log_returns, label='Log Returns')\n","        axs[0].axhline(mu - 1*sigma, color='b', linestyle='--', label=f'μ - 1σ = {mu - 3*sigma:.4f}')\n","        axs[0].axhline(mu + 1*sigma, color='b', linestyle='--', label=f'μ + 1σ = {mu + 3*sigma:.4f}')\n","        axs[0].set_title('Daily Log Returns (Time Series)', fontsize=14)\n","        axs[0].set_xlabel('Date')\n","        axs[0].set_ylabel('Log Return')\n","        axs[0].legend()\n","        axs[0].grid(True)\n","\n","        # ─────────────────────────────\n","        # 2️⃣ Histogram + Gaussian Fit\n","        x = np.linspace(self.log_returns.min(), self.log_returns.max(), 1000)\n","        pdf = stats.norm.pdf(x, mu, sigma)\n","\n","        axs[1].hist(log_returns_values, bins=50, density=True, alpha=0.6, edgecolor='k', label='Histogram')\n","        axs[1].plot(x, pdf, 'r-', label=f'Gaussian Fit\\nμ={mu:.4f}, σ={sigma:.4f}')\n","        axs[1].axvline(mu - 1*sigma, color='b', linestyle='--', label=f'μ - 1σ = {mu - 3*sigma:.4f}')\n","        axs[1].axvline(mu + 1*sigma, color='b', linestyle='--', label=f'μ + 1σ = {mu + 3*sigma:.4f}')\n","        axs[1].set_title('Log Returns Distribution & Gaussian Fit', fontsize=14)\n","        axs[1].set_xlabel('Log Return')\n","        axs[1].set_ylabel('Density')\n","        axs[1].legend()\n","        axs[1].grid(True)\n","\n","        # ─────────────────────────────\n","        # 3️⃣ Q-Q Plot\n","        stats.probplot(log_returns_values, dist=\"norm\", plot=axs[2])\n","        axs[2].get_lines()[1].set_color('red')  # Line of best fit\n","        axs[2].set_title('Q-Q Plot of Log Returns', fontsize=14)\n","        axs[2].grid(True)\n","\n","        # Show all\n","        plt.show()\n","\n","        self.mu_prior = mu_annual\n","        self.sigma_prior = sigma_annual\n","\n","        threshold = 3 * sigma\n","        #Create binary jump indicator\n","        jump_indicator = (np.abs(self.log_returns - mu) > threshold).astype(int)\n","\n","        #Resample by year and count jumps\n","        yearly_jump_counts = jump_indicator.resample('YE').sum()\n","        yearly_jump_counts.index = yearly_jump_counts.index.year\n","\n","        sorted = yearly_jump_counts.sort_index()\n","\n","        #Estimate λ (Poisson mean)\n","        # Remove outliers using IQR method\n","        qv1 = sorted.quantile(0.0)\n","        qv2 = sorted.quantile(0.75)\n","        iqr = qv2 - qv1\n","        lower_bound = qv1 - 0 * iqr\n","        upper_bound = qv2 + 0 * iqr\n","\n","        # Filter out outliers\n","        filtered_sorted = sorted[(sorted >= lower_bound) & (sorted <= upper_bound)]\n","        yearly_jump_counts_values = filtered_sorted.values\n","\n","        lambda_j = yearly_jump_counts_values.mean()\n","\n","        ###\n","        # Theoretical quantiles from Poisson\n","        n = len(yearly_jump_counts_values)\n","        quantiles = np.linspace(0.01, 0.99, n)\n","        percentiles = np.quantile(yearly_jump_counts_values, quantiles)\n","        theoretical_q = stats.poisson.ppf(quantiles, mu=lambda_j)\n","\n","        # Create subplots\n","        fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n","\n","        # --- Plot 1: Histogram with Poisson PMF ---\n","        axs[0].hist(yearly_jump_counts_values, bins=range(int(max(yearly_jump_counts_values))+2),\n","                    density=True, alpha=0.6, edgecolor='k', label='Observed')\n","\n","        x = np.arange(0, max(yearly_jump_counts_values)+1)\n","        pmf = stats.poisson.pmf(x, mu=lambda_j)\n","        axs[0].plot(x, pmf, 'ro-', label=f'Poisson PMF (λ={lambda_j:.2f})')\n","\n","        axs[0].set_title(\"Poisson Fit to Yearly Jump Counts\")\n","        axs[0].set_xlabel(\"Jump Count per Year\")\n","        axs[0].set_ylabel(\"Probability\")\n","        axs[0].legend()\n","        axs[0].grid(True)\n","\n","        # --- Plot 2: Q-Q Plot ---\n","        axs[1].plot(theoretical_q, percentiles, 'bo', label='Empirical vs Poisson')\n","        axs[1].plot([0, max(theoretical_q.max(), yearly_jump_counts_values.max())],\n","                    [0, max(theoretical_q.max(), yearly_jump_counts_values.max())],\n","                    'r--', label='Ideal Fit (y = x)')\n","\n","        axs[1].set_title(\"Q-Q Plot: Empirical vs Poisson Quantiles\")\n","        axs[1].set_xlabel(\"Theoretical Quantiles (Poisson)\")\n","        axs[1].set_ylabel(\"Empirical Quantiles (Observed)\")\n","        axs[1].legend()\n","        axs[1].grid(True)\n","\n","        plt.tight_layout()\n","        plt.show()\n","\n","        # Estimate mu_J and sigma_J (jump size stats)\n","        jump_sizes = self.log_returns.loc[np.abs(self.log_returns - mu) > threshold].dropna() #Extract jump sizes\n","\n","        sorted = jump_sizes.sort_index()\n","\n","        # Remove outliers using IQR method\n","        qv1 = sorted.quantile(0.25)\n","        qv2 = sorted.quantile(0.75)\n","        iqr = qv2 - qv1\n","        lower_bound = qv1 - 2.5 * iqr\n","        upper_bound = qv2 + 2.5 * iqr\n","\n","        # Filter out outliers\n","        filtered_sorted = sorted[(sorted >= lower_bound) & (sorted <= upper_bound)]\n","        jump_sizes_values = filtered_sorted.values\n","\n","        # Fit normal distribution\n","        mu_J, sigma_J = norm.fit(jump_sizes_values)\n","\n","        # Create subplots: 1 row, 2 columns\n","        fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n","\n","        # Histogram with fitted normal curve\n","        axs[0].hist(jump_sizes_values, bins=20, density=True, alpha=0.6, color='skyblue', edgecolor='black')\n","        xmin, xmax = axs[0].get_xlim()\n","        x = np.linspace(xmin, xmax, 100)\n","        p = norm.pdf(x, mu_J, sigma_J)\n","        axs[0].plot(x, p, 'r', linewidth=2)\n","        axs[0].set_title(\"Histogram of Jump Sizes with Fitted Normal Curve\")\n","        axs[0].set_xlabel(\"Jump Size\")\n","        axs[0].set_ylabel(\"Density\")\n","        axs[0].grid(True)\n","        # Add mu_J and sigma_J to the plot\n","        textstr = f\"$\\\\mu_J$ = {mu_J:.4f}\\n$\\\\sigma_J$ = {sigma_J:.4f}\"\n","        axs[0].text(0.95, 0.95, textstr,\n","                    transform=axs[0].transAxes,\n","                    fontsize=12,\n","                    verticalalignment='top',\n","                    horizontalalignment='right',\n","                    bbox=dict(boxstyle=\"round\", facecolor=\"white\", edgecolor=\"gray\", alpha=0.8))\n","\n","        # Q-Q plot\n","        probplot(jump_sizes_values, dist=\"norm\", sparams=(mu_J, sigma_J), plot=axs[1])\n","        axs[1].set_title(\"Q-Q Plot vs Fitted Normal\")\n","        axs[1].grid(True)\n","\n","        plt.tight_layout()\n","        plt.show()\n","\n","        self.mu_j_prior = mu_J\n","        self.sigma_j_prior = sigma_J\n","        self.lamda_j_prior = lambda_j\n","\n","        return self.mu_prior, self.sigma_prior, self.mu_j_prior, self.sigma_j_prior, self.lamda_j_prior\n","\n","\n","    \"\"\"Fit a Bayesian model to estimate mu and sigma.\"\"\"\n","    def fit_bayesian_model_GBM(self, nsample, nburn, nchain):\n","        mu_prior = self.mu_prior/252\n","        sigma_prior = self.sigma_prior/np.sqrt(252)\n","        with pm.Model() as model:\n","\n","            # Prior for mu\n","            mu = pm.Normal(\"mu\", mu=mu_prior, sigma=sigma_prior)\n","\n","            #Prior for sigma\n","            #sigma_squared = pm.InverseGamma(\"sigma_squared\", alpha=2, beta=self.sigma_prior)\n","            #sigma = pm.Deterministic(\"sigma\", pm.math.sqrt(sigma_squared))\n","\n","            sigma = pm.HalfNormal(\"sigma\", sigma=sigma_prior)\n","\n","            # Likelihood (observed log returns)\n","            obs = pm.Normal(\"obs\", mu=mu, sigma=sigma, observed=self.log_returns)\n","\n","            # Sampling (using Metropolis algorithm)\n","            step = pm.Metropolis()\n","            trace = pm.sample(nsample+nburn, step=step, tune=nburn, chains=nchain, return_inferencedata=True, random_seed=42)\n","\n","        az.plot_trace(trace, var_names=[\"mu\", \"sigma\"])\n","        plt.tight_layout()\n","        plt.show()\n","        az.plot_autocorr(trace, var_names=[\"mu\", \"sigma\"])\n","        plt.tight_layout()\n","        plt.show()\n","        summary = az.summary(trace, var_names=[\"mu\", \"sigma\"], round_to=4)\n","        print(summary)\n","\n","        # Extract posterior samples\n","        mu_samples = trace.posterior['mu'].values.flatten()\n","        sigma_samples = trace.posterior['sigma'].values.flatten()\n","\n","        self.mu_samples = mu_samples * 252\n","        self.sigma_samples = sigma_samples *np.sqrt(252)\n","\n","        return self.mu_samples, self.sigma_samples\n","\n","\n","    \"\"\"Fit a Bayesian model to estimate mu, sigma, jump params\"\"\"\n","    def fit_bayesian_model_Merton(self, nsample, nburn, nchain):\n","        mu_prior = self.mu_prior/252\n","        sigma_prior = self.sigma_prior/np.sqrt(252)\n","        mu_j_prior = self.mu_j_prior\n","        sigma_j_prior = self.sigma_j_prior\n","        lamda_j_prior = self.lamda_j_prior / 252\n","\n","        y = self.log_returns.values  # observed data\n","\n","        with pm.Model() as model:\n","            # Priors\n","            mu = pm.Normal(\"mu\", mu=mu_prior, sigma=sigma_prior)\n","            sigma = pm.HalfNormal(\"sigma\", sigma=sigma_prior)\n","            mu_j = pm.Normal(\"mu_j\", mu=mu_j_prior, sigma=sigma_j_prior)\n","            sigma_j = pm.HalfNormal(\"sigma_j\", sigma=sigma_j_prior)\n","            lambda_j = pm.Exponential(\"lambda_j\", lam=lamda_j_prior)\n","\n","            # Custom log-likelihood\n","            def merton_logp(value, mu, sigma, lambda_j, mu_j, sigma_j, dt):\n","                i_max = 2\n","                kappa = pt.exp(mu_j + 0.5 * sigma_j**2) - 1\n","                logp_components = []\n","\n","                for i in range(i_max + 1):\n","                    mu_poisson = lambda_j * dt\n","                    log_poisson_prob = pm.logp(pm.Poisson.dist(mu=lambda_j * dt), pt.constant(i, dtype='int64'))\n","\n","                    mean_k = (mu - 0.5 * sigma**2 - lambda_j * kappa) * dt + i * mu_j\n","                    var_k = sigma**2 * dt + i * sigma_j**2\n","                    std_k = pt.sqrt(var_k)\n","\n","                    log_normal_prob_vec = pm.logp(pm.Normal.dist(mu=mean_k, sigma=std_k), value)\n","                    log_joint_prob_vec = log_normal_prob_vec + log_poisson_prob\n","                    logp_components.append(log_joint_prob_vec)\n","\n","                logp_matrix = pt.stack(logp_components)\n","                log_likelihood_per_obs = pt.logsumexp(logp_matrix, axis=0)\n","                return pt.sum(log_likelihood_per_obs)\n","\n","            # Register as potential\n","            pm.Potential(\"likelihood\", merton_logp(y, mu, sigma, lambda_j, mu_j, sigma_j, 1/252))\n","\n","            # Sampling\n","            step = pm.Metropolis()\n","            trace = pm.sample(nsample + nburn, step=step, tune=nburn, chains=nchain,\n","                              return_inferencedata=True, random_seed=42)\n","\n","        # Plotting\n","        az.plot_trace(trace, var_names=[\"mu\", \"sigma\", \"lambda_j\", \"mu_j\", \"sigma_j\"])\n","        plt.tight_layout()\n","        plt.show()\n","\n","        az.plot_autocorr(trace, var_names=[\"mu\", \"sigma\", \"lambda_j\", \"mu_j\", \"sigma_j\"])\n","        plt.tight_layout()\n","        plt.show()\n","\n","        summary = az.summary(trace, var_names=[\"mu\", \"sigma\", \"lambda_j\", \"mu_j\", \"sigma_j\"], round_to=4)\n","        print(summary)\n","\n","        # Rescale to annualized units\n","        self.mu_samples = trace.posterior[\"mu\"].values.flatten() * 252\n","        self.sigma_samples = trace.posterior[\"sigma\"].values.flatten() * np.sqrt(252)\n","        self.mu_j_samples = trace.posterior[\"mu_j\"].values.flatten()\n","        self.sigma_j_samples = trace.posterior[\"sigma_j\"].values.flatten()\n","        self.lamda_j_samples = trace.posterior[\"lambda_j\"].values.flatten() * 252\n","\n","        return self.mu_samples, self.sigma_samples, self.mu_j_samples, self.sigma_j_samples, self.lamda_j_samples\n"],"metadata":{"id":"KwMsIKR761Nh"},"execution_count":null,"outputs":[]}]}